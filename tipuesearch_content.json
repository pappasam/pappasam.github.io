{"pages":[{"title":"About","text":"Headshot: Sam Roeca. Photo credit: Grant Germano . My name is Samuel Roeca. I am the Director of Engineering at Kepler Group LLC , a tech-driven digital marketing agency. I live in New York city and love it here! In my free time, I like playing squash , tweaking my vimrc , skiing, and writing.","tags":"pages","url":"https://softwarejourneyman.com/pages/about.html"},{"title":"Python Function Pipelines","text":"If your Python code represents a function pipeline, it should look like a function pipeline. This post presents a simple, strongly-typed function pipeline for your personal projects to make beautiful, explicit, Unix-like pipelines in Python. Requires Python 3.6 or greater. I was reading through the pytorch reinforcement learning documentation today and came across the following irksome pattern: ... def forward ( self , x ): x = F . relu ( self . bn1 ( self . conv1 ( x ))) x = F . relu ( self . bn2 ( self . conv2 ( x ))) x = F . relu ( self . bn3 ( self . conv3 ( x ))) return self . head ( x . view ( x . size ( 0 ), - 1 )) .. The manipulation and reassignment of a variable x to itself as it is passed through a neural network's gateways makes neural networks that much harder to follow. IMHO, explicit variable reassignment is almost always bad because it makes it hard for my limited human brain to track a variable name's associated data during program execution. If a program tells me that x is an integer on line 10 and then reassigns it to a string on line 20, I will want to delete said program from my computer, take a cold shower, and exact revenge on the program's author. With that established, let's just avoid reassignment altogether. The problem In the above example, variable reassignment is convenient. It prevents the programmer from needing to come up with new names for each state in the connected pipeline. How can we find an elegant way of avoiding explicit variable reassignment in the pipeline use-case while still producing readable, performant code? The answer: take inspiration from Unix pipes! Unix pipes In the Unix shell, virtually everything we work with has the same type: a file . \"Everything is a File\" makes it easy to chain functions together because all commands take files as inputs and return files as outputs. One common way to chain system calls in Unix is called the anonymous pipe , which enables programmers to chain command line programs together to manipulate a text stream. See the following example: #!/bin/bash # Count the number of words echo \"hello hello hello world world\" | wc -w # Count the number of words that are not \"hello\" echo \"hello hello hello world world\" | sed 's/hello//g' | wc -w # Count the number of words that are not \"world\" echo \"hello hello hello world world\" | sed 's/world//g' | wc -w # Should print the following to console: # 5 # 2 # 3 Notice that data flows through the pipeline and no variable reassignment is used. The Unix pipeline is beautiful in this regard; I'd like to build something similar in Python. Example Let's say we have the following three functions: def add_5 ( value : int ) -> int : return value + 5 def add_6 ( value : int ) -> int : return value + 6 def add_7 ( value : int ) -> int : return value + 7 Our example problem : take an initial integer 0 and add 5, then 6, then 7 to it using our three functions so that our final result is 18. Solution 1: name each step in the pipeline We can do slightly better than the pytorch example and create a unique variable name for each step in the process. x_0 = 0 x_5 = add_5 ( x_0 ) x_6 = add_6 ( x_5 ) x = add_7 ( x_6 ) print ( f 'x={x}' ) Besides being pretty ugly / hard to read, this creates some useless names in our module's scope. Do we really need to give each step its own name? We don't use the steps anywhere else and this makes the pipeline pretty hard to edit. This solution almost makes we wish we could go back to reassignment. Fortunately, the entire pipeline can be expressed with one name thanks to the \"reduce\" function. Solution 2: use the \"reduce\" function from functools import reduce y = reduce ( lambda value , function : function ( value ), ( add_5 , add_6 , add_7 , ), 0 , ) print ( f 'y={y}' ) This example uses the standard library \"reduce\" function. Originally, \"reduce\" was intended to take a list of values and collapse them into one value. This use-case is described well in the Python documentation and in this YouTube video. Here, we use it a bit differently. Instead of taking a list of values and applying a \"collapsing\" function to them, we take a list of functions and pass a value through them. This has obvious advantages over solution 1: we can easily swap new functions in and out of the pipeline to suit our needs without needing to adjust any other code / rename pipeline steps (because we haven't named the steps at all!). This solution frees us from naming each step in our pipeline but it does have some disadvantages: \"reduce\" is kind of hard to read and this use-case isn't quite standard. Whenever we find ourselves using a standard library function in a confusing way, that's a signal that we should probably define our own function to make this clearer to ourselves and to those who read our code. Solution 3: custom \"pipeline\" function from typing import TypeVar , Callable , Sequence T = TypeVar ( 'T' ) def pipeline ( value : T , function_pipeline : Sequence [ Callable [[ T ], T ]], ) -> T : '''A generic Unix-like pipeline :param value: the value you want to pass through a pipeline :param function_pipeline: an ordered list of functions that comprise your pipeline ''' return reduce ( lambda v , f : f ( v ), function_pipeline , value ) z = pipeline ( value = 0 , function_pipeline = ( add_5 , add_6 , add_7 , ) ) print ( f 'z={z}' ) This solution is elegant and explicit. It is generic and works with mypy. As long as our function pipeline contains only functions that take our value's type and return our value's type (similar to Unix command line utilities, where everything is a file), this pipeline will successfully pass our value in a type-safe way. Full script #!/usr/bin/env python '''Simple function example''' # functions: begin def add_5 ( value : int ) -> int : return value + 5 def add_6 ( value : int ) -> int : return value + 6 def add_7 ( value : int ) -> int : return value + 7 # functions: end # reassignment: begin x_0 = 0 x_5 = add_5 ( x_0 ) x_6 = add_6 ( x_5 ) x = add_7 ( x_6 ) print ( f 'x={x}' ) # reassignment: end # simple reduce: begin from functools import reduce y = reduce ( lambda value , function : function ( value ), ( add_5 , add_6 , add_7 , ), 0 , ) print ( f 'y={y}' ) # simple reduce: end # pipeline: begin from typing import TypeVar , Callable , Sequence T = TypeVar ( 'T' ) def pipeline ( value : T , function_pipeline : Sequence [ Callable [[ T ], T ]], ) -> T : '''A generic Unix-like pipeline :param value: the value you want to pass through a pipeline :param function_pipeline: an ordered list of functions that comprise your pipeline ''' return reduce ( lambda v , f : f ( v ), function_pipeline , value ) z = pipeline ( value = 0 , function_pipeline = ( add_5 , add_6 , add_7 , ) ) print ( f 'z={z}' ) # pipeline: end Conclusion If your system resembles a pipeline, don't reassign your piped variable to itself. There is a better way and it's pretty much built into Python. You'll just need to care enough to use it.","tags":"Software Development","url":"https://softwarejourneyman.com/python-function-pipelines.html"},{"title":"Smaller Python Docker Containers with Multi-Stage Builds and Python Wheels","text":"If your Docker Python build requires system dependencies that are NOT required at runtime, structure your build as follows: Use a multi-stage build Stage 1 installs system dependencies and uses them to build local wheels Stage 2 begins from the same base as Stage 1, copies wheels from Stage 1, and installs the wheels The rest of your build will be based on Stage 2 If you follow these steps, you'll end up with the smallest-possible Python Docker container with all your Python dependencies intact. Note: this post references Docker 18.03, Python 3.6, and pip 10. I assume that you are running CPython (Python's reference implementation). The problem We want to do a Python system build using Docker. Python system builds often require installing third-party code. This third-party code may contain code or resources that must be compiled during their installation. For simplicity's sake, assume we are talking about source code in the C programming language. Since a Docker container will be our \"target machine\", we'll need a C compiler in our Docker container. Unfortunately, C compilers are large programs. Since we plan to scale our number of containers up and down based on the demand for its provided service, the image should ideally be as small as possible. Basically, we want to build C code with a C compiler and then throw away the C compiler to save space in our deployment image. Examples The following examples should clarify the problem and its resolution. Note: I'm assuming that you're using a POSIX -inspired system. Setup Copy the following Makefile into your current working directory. .PHONY : build - break build-break : docker build -t blog-python:break -f ./Dockerfile.break . .PHONY : build - big build-big : docker build -t blog-python:big -f ./Dockerfile.big . docker images .PHONY : build - uninstall - big build-uninstall-big : docker build -t blog-python:big-uninstall -f ./Dockerfile.uninstall . docker images .PHONY : build - small build-small : docker build -t blog-python:small -f ./Dockerfile.small . docker images Example 1: broken build requiring a C compiler We have a simple, entrypoint -less Docker container in which we must install uWSGI . In the uWSGI quickstart guide, its developers clarify that it \"is a (big) C application, so you need a C compiler (like gcc or clang) and the Python development headers\". Copy the following code into a file called \"Dockerfile.break\": FROM python:3.6-alpine as breakimage RUN pip install uwsgi Now run the following shell command in the same directory as your Dockerfile.break. make build-break At the end of our failed build, we see this Traceback (in addition to other helpful messages): Traceback (most recent call last): File \"<string>\" , line 1 , in <module> File \"/tmp/pip-install-tkd8plx9/uwsgi/setup.py\" , line 137 , in <module> 'Programming Language :: Python :: 3.6' , File \"/usr/local/lib/python3.6/site-packages/setuptools/__init__.py\" , line 129 , in setup return distutils . core . setup ( ** attrs ) File \"/usr/local/lib/python3.6/distutils/core.py\" , line 148 , in setup dist . run_commands () File \"/usr/local/lib/python3.6/distutils/dist.py\" , line 955 , in run_commands self . run_command ( cmd ) File \"/usr/local/lib/python3.6/distutils/dist.py\" , line 974 , in run_command cmd_obj . run () File \"/tmp/pip-install-tkd8plx9/uwsgi/setup.py\" , line 77 , in run conf = uc . uConf ( get_profile ()) File \"/tmp/pip-install-tkd8plx9/uwsgi/uwsgiconfig.py\" , line 747 , in __init__ raise Exception ( \"you need a C compiler to build uWSGI\" ) Exception : you need a C compiler to build uWSGI Consistent with the uWSGI documentation, our system has said that we \"need a C compiler to build uWSGI\". We'll do that in example 2. Example 2: large build with C compiler installed In this example, we'll install our system dependencies so uWSGI can actually be built. Copy the following code into a file called \"Dockerfile.big\": FROM python:3.6-alpine as bigimage RUN apk add --no-cache linux-headers g++ RUN pip install uwsgi Now run the following shell command: make build-big In the \"build-big\" make target, I've included a command to list all Docker images on your system. Because of this command, you should see something close to the following in your terminal: REPOSITORY TAG IMAGE ID CREATED SIZE blog-python big 8a68d0dad407 Less than a second ago 251MB python 3.6-alpine 8eb1c554687d 16 hours ago 90.4MB The good The image built successfully. The bad The image is unnecessarily large. We're planning on scaling our web-service to handle a decent amount of traffic. Scaling will involve deploying many images on many servers. Larger images take longer to deploy and (obviously) take up more space than smaller images. The ugly We are including an unnecessary dependency. We don't need a C compiler in the image, so the C compiler is an unnecessary dependency. Including an unnecessary dependency in our runtime image is a horrible design, similar to including an unnecessary Python dependency in our requirements.txt or setup.py. As great software developers, we HATE bad system design, so let's find a way to resolve the \"bad\" and the \"ugly\" while preserving the \"good\"! Example 3: failed attempt at simply \"uninstalling\" C compiler Unfortunately, if we want to reduce our image size, we cannot simply \"uninstall\" the C compiler. For reasons that I do not fully comprehend at this time, Docker caches anything you install in an image, so uninstalling a dependency does NOT reduce the image size. Copy the following code into a file called \"Dockerfile.uninstall\": FROM python:3.6-alpine as bigimage-uninstalled RUN apk add --no-cache linux-headers g++ RUN pip install uwsgi RUN apk del linux-headers g++ Now run the following shell command: make build-uninstall-big You should see something close to the following in your terminal: REPOSITORY TAG IMAGE ID CREATED SIZE blog-python big-uninstall 10a0eb5d42aa Less than a second ago 251MB blog-python big 8a68d0dad407 11 minutes ago 251MB python 3.6-alpine 8eb1c554687d 16 hours ago 90.4MB Our efforts at removing our C compiler proved futile. At this point, lesser developers would give up and assume we've reached the end of the road. But you, dear reader, are reading my blog, and I know you're better than that! Let's dig deeper and find an elegant way shrink our Docker image! Example 4: small final build without C compiler This final example results in a small image with uWSGI installed and without a C compiler. It relies heavily on multi-stage builds and on pip wheels. Copy the following code into a file called \"Dockerfile.small\": ########################################### # Throwaway image with C compiler installed FROM python:3.6-alpine as bigimage # instead of installing, create a wheel RUN pip wheel --wheel-dir = /root/wheels uwsgi ########################################### # Image WITHOUT C compiler but WITH uWSGI FROM python:3.6-alpine as smallimage COPY --from = bigimage /root/wheels /root/wheels # Ignore the Python package index # and look for archives in # /root/wheels directory RUN pip install \\ --no-index \\ --find-links = /root/wheels \\ uwsgi Now run the following shell command: make build-small You should see something close to the following in your terminal: REPOSITORY TAG IMAGE ID CREATED SIZE blog-python small b952f6280b00 1 second ago 97.4MB <none> <none> 91c7bb911f32 3 minutes ago 249MB blog-python big-uninstall 10a0eb5d42aa 23 minutes ago 251MB blog-python big 8a68d0dad407 34 minutes ago 251MB python 3.6-alpine 8eb1c554687d 16 hours ago 90.4MB Notice that the image tagged \"small\" is ~61% smaller than its \"big\" counterparts. It has 7 additional MB from its base alpine container. These megabytes represent only the uWSGI library itself. We'll need to make modifications to uWSGI itself to get any smaller. I leave uWSGI modifications as an exercise for the reader. Explanation Two key points are responsible for our Docker build's success: Reliance on copying between image stages in Docker multi-stage builds. This gets around caching problems with a single image Understanding the difference between \"pip install\" and \"pip wheel\" Copying betwen Docker build stages in multi-stage build Unless we explicitly specify a --target , Docker multi-stage builds will tag their last stage. Downstream build stages can reference upstream build stages and copy resources from them, similarly to how resources can be copied from any local or remote file system into a traditional Docker container. Therefore, we \"compile\" our Python code in one build stage and copy this compiled code in another build stage. Since the code no longer needs to be compiled, we don't need to a C compiler or Linux headers. As the coup de grâce, our build's final stage is not based on any image with a C compiler installed, so this approach completely avoids Docker's caching complexities. Thanks to Docker's multi-stage builds, we are able to compile our Python package and avoid deploying the build's system dependencies in our final image. Difference between \"pip install\" and \"pip wheel\" Docker multi-stage builds are cool and all, but I've seen many articles about them. Python's packaging tool, pip , hasn't gotten as much careful attention from the blogging community. Hopefully this section can clear up one common point of confusion: pip install vs pip wheel . pip install This is the command most people are familiar with. At a high level, it takes a Python package, runs its setup.py, downloads and installs its dependencies, and potentially does a lot more. Run \"pip install\" when you want to expand a package's contents and use it as its author intended. A good mental model: \"pip install\" takes a consolidated bundle of code / build instructions and places the package's content and dependencies wherever they need to go on an operating system. Once \"pip install\" runs on our machine, file placement throughout our file system can be pretty hamajang , depending on a package's setup.py instructions. pip wheel This tool is mostly used by library developers wanting to distribute their packages in a user-friendly way. For example, scikitlearn , a popular Python library for machine learning, requires a lot of system dependencies to build. Many Python users, especially data scientists, are either unwilling or unable to install these dependencies on their host machines. This user-characteristic led to unfortunate platforms like Anaconda (author opinion). On a more mature note, for those of us with the appropriate dependencies installed, the installation process would often take a very long time; C, FORTRAN, and possibly other languages each needed to be compiled, and installing code written in these languages often leads to a long coffee break. Wheels enable Python developers to compile a package, and its dependencies, in a distributable form targeting common operating system architectures. Today, most scikitlearn users install it using its wheel , which takes a fraction of the time of the regular build process. A good mental model: \"pip wheel\" takes a Python package, makes it ready to be installed on any target machine WITHOUT its build dependencies, and puts it in ONE easily-distributed archive file. Why we care about this? Not all Python packages are distributed as wheels. There are some packages, based mostly on C, that are hard to compile once and use in many places. uWSGI appears to be one of those packages. To build our final image, we construct a throw-away container to construct a wheel for uWSGI. Conclusion When building a Docker container for a Python application, we can install packages requiring build-time system dependencies AND remove these system dependencies from our final Docker image through a combination of Docker multi-stage builds, pip wheel, and pip install. Special thanks This post took inspiration from this post by Alejandro Guirao. I am indebted to Alejandro for publishing his creative use of docker multi-stage builds in the context of Python systems.","tags":"Software Development","url":"https://softwarejourneyman.com/docker-python-install-wheels.html"},{"title":"Vim Line Numbers","text":"If you want your Vim line numbers to be relative and/or not relative at the correct times, I recommend installing the myusuf3/numbers.vim plugin. The Problem When editing text in a Vim window, I use relative numbers to help me use motions across text relative to my cursor. However, when I have multiple windows open, relative numbers look pretty weird in windows that I am not currently editing. It would be nice for Vim to intelligently alternate between relativenumber and norelativenumber based on my Vim cursor location. Base Vim does not have this capability, so we have three options: Accept a suboptimal workflow Wrap our own solution in our .vimrc Find a Plugin I lived with option 1 for a while, but eventually grew too annoyed. I then tried researching plugins, but thought I understood the problem well-enough to write my own solution. So I went straight to option 2 and tried wrapping my own solution. Wrapping my own solution The following code represents my original solution: 1 function ! ToggleRelativeNumber () 2 if & rnu 3 set norelativenumber 4 else 5 set relativenumber 6 endif 7 endfunction 8 9 function ! RNUInsertEnter () 10 if & rnu 11 let w :line_number_state = 'rnu' 12 set norelativenumber 13 else 14 let w :line_number_state = 'nornu' 15 endif 16 endfunction 17 18 function ! RNUInsertLeave () 19 if w :line_number_state == 'rnu' 20 set relativenumber 21 else 22 set norelativenumber 23 let w :line_number_state = 'nornu' 24 endif 25 endfunction 26 27 function ! RNUWinEnter () 28 if exists ( 'w:line_number_state' ) 29 if w :line_number_state == 'rnu' 30 set relativenumber 31 else 32 set norelativenumber 33 endif 34 else 35 set relativenumber 36 let w :line_number_state = 'rnu' 37 endif 38 endfunction 39 40 function ! RNUWinLeave () 41 if & rnu 42 let w :line_number_state = 'rnu' 43 else 44 let w :line_number_state = 'nornu' 45 endif 46 set norelativenumber 47 endfunction 48 49 \" autocmd that will set up the w:created variable 50 autocmd VimEnter * autocmd WinEnter * let w :created = 1 51 autocmd VimEnter * let w :created = 1 52 set number relativenumber 53 augroup rnu_nu 54 autocmd ! 55 \"Initial window settings 56 autocmd WinEnter * if ! exists ( 'w:created' ) | 57 \\ setlocal number relativenumber | 58 \\ endif 59 autocmd User Startified setlocal number relativenumber 60 \" Don't have relative numbers during insert mode 61 autocmd InsertEnter * : call RNUInsertEnter () 62 autocmd InsertLeave * : call RNUInsertLeave () 63 \" Set and unset relative numbers when buffer is active 64 autocmd WinEnter * : call RNUWinEnter () 65 autocmd WinLeave * : call RNUWinLeave () 66 augroup end The good The solution worked for most windows and tabs, most of the time. The bad The code is a bit involved and it takes a little time to explain to others. It relies on window-local variables (w:line_number_state, etc). These exacerbate Vim's already-difficult state-management woes. Several global functions are defined There are some quirks I don't fully understand around the creation of variables during Vim startup (hence lines 50 and 51). Despite these mild downsides, I was pretty proud that the solution mostly worked. That is, until I wasn't. The back-breaking straw My custom solution did not work appropriately with some of my plugins. Namely, it didn't play well with majutsushi/tagbar , which I use frequently enough for this feature-dearth to become royally annoying. Therefore, after learning the ins-and-outs of window-specific variables and every Vim autocmd, I went back to the Plugin ecosystem to see if I'd missed anything... The Game-Changing Plugin Turns out a wonderful developer already solved this problem for me. Assuming you use junegunn/vim-plug to manage your plugins, place the following code in your .vimrc call plug#begin ( '~/.vim/plugged' ) \" Relative Numbering Plug 'myusuf3/numbers.vim' \" Put the rest of your plugins below... call plug# end () \" Now, exclude the plugins you don't want numbers to deal with let g :numbers_exclude = [ 'startify' , 'gundo' , 'vimshell' ] This will give you a great editing experience. See below for a screencast: Conclusion Numbers.vim provides a usable line-numbering solution with minimal required configuration. I regret nothing about my bespoke journey, but I'm glad that Numbers.vim is my destination.","tags":"Software Development","url":"https://softwarejourneyman.com/vim-line-numbers.html"}]}